# üöÄ SPRINT II - Introdu√ß√£o √† An√°lise de Dados com Python

Ol√°, pessoal! Bem-vindos a este reposit√≥rio. O objetivo √© explicar um pouco sobre o universo da an√°lise de dados, mostrando um fluxo de trabalho b√°sico.


## üìñ Por que An√°lise de Dados?

Vivemos na era dos dados. Cada clique, cada compra online, cada rota no GPS gera um volume gigantesco de informa√ß√µes. Diante disso, √© preciso saber extrair as informa√ß√µes, encontrar padr√µes e transformar esse ru√≠do em conhecimento.


Esse conhecimento nos ajuda a tomar decis√µes mais inteligentes, otimizar produtos e fazer novas descobertas.


√â nesse contexto que entram as bibliotecas que vamos usar: **NumPy** e **Pandas**.


Para escrever e executar os c√≥digos em Python, podemos instalar no computador o Anaconda, uma distribui√ß√£o do Python, e escolher a ferramenta JupyterLab. Por√©m, voc√™s tamb√©m podem optar pelo Google Colab, um servidor que tamb√©m permite escrever e executar c√≥digo em Python diretamente no seu navegador. √â s√≥ digitar Google Colab no Google que o servidor aparece.



## üõ†Ô∏è Ferramenta 1: NumPy (Python Num√©rico)


O NumPy √© a biblioteca fundamental para computa√ß√£o num√©rica em Python.


Ele trabalha com matrizes e arranjos multidimensionais, permitindo c√°lculos r√°pidos e eficientes. Sua grande vantagem s√£o as "opera√ß√µes vetorizadas", onde c√°lculos (como somas ou multiplica√ß√µes) s√£o aplicados a todos os elementos simultaneamente.


### Pr√°tica com NumPy


Primeiro, importamos a biblioteca:


Usamos 'np' como um apelido (para n√£o precisar repetir 'numpy' novamente).

```python
import numpy as np
```
1. Criando um Array Simples

   
Vamos criar um array (um vetor) de 1 dimens√£o. 


Todos os valores devem ser do mesmo tipo, por exemplo, todos os n√∫meros decimais ou todos os n√∫meros inteiros.


```python
# Criando um array simples de n√∫meros inteiros
arr = np.array([10, 20, 30, 40, 50], np.int16)
print("Array:", arr)
```


Ao executar o c√≥digo, podemos ver o resultado. Note que aparecem os n√∫meros escolhidos.


2. Opera√ß√µes Vetorizadas


Veja como √© f√°cil aplicar opera√ß√µes a todos os n√∫meros de uma vez:
```python
# Opera√ß√µes matem√°ticas vetorizadas
print("Multiplicado por 2:", arr * 2)
print("Soma total:", arr.sum())
print("M√©dia:", arr.mean())
print("Desvio padr√£o:", arr.std())
```


Percebam que o NumPy multiplicou cada n√∫mero do array por 2. Depois, o numpy somou todos os n√∫meros que est√£o dentro do array, obtendo um valor de 150. Ap√≥s isso, ele somou o valor total de 150 e dividiu pela quantidade de n√∫meros (5), obtendo assim o valor da m√©dia. E, por fim, ele mediu o qu√£o ‚Äúdispersos‚Äù est√£o os dados em rela√ß√£o √† m√©dia, fornecendo o valor do desvio padr√£o.


Agora iremos fazer um pouco diferente, ao inv√©s de criarmos um array de uma dimens√£o, como fizemos antes, vamos criar um array bidimensional, tamb√©m chamado de matriz. Uma estrutura composta de valores organizados em linhas e colunas, no nosso caso, vamos criar uma matriz de 2 linhas e 3 colunas.


3. Matrizes (Array Bidimensional)


Tamb√©m podemos criar matrizes (linhas e colunas):

```python
# Criando uma matriz de 2 linhas e 3 colunas
matriz = np.array([[1, 2, 3], [4, 5, 6]])
print("Matriz:\n", matriz)

# '.T' calcula a transposta (inverte linhas e colunas)
print("Transposta:\n", matriz.T)
```


A forma como voc√™ agrupa os n√∫meros nos colchetes vai definir exatamente como essa matriz ser√° montada. Percebam que temos duas listas internas. A primeira, [1, 2, 3], se torna a primeira linha, e a segunda, [4, 5, 6], se torna a segunda linha.


Observem tamb√©m que o n√∫mero de elementos dentro de cada linha define o n√∫mero de colunas. Como cada linha tem 3 n√∫meros, a nossa matriz tem 3 colunas. 


Quando usamos o comando T, realizamos o processo de transposi√ß√£o. Basicamente, as linhas da matriz original se tornam as colunas da nova matriz. Como a nossa matriz original tinha 2 linhas e 3 colunas, a transposta passar√° a ter 3 linhas e 2 colunas.


## üõ†Ô∏è Ferramenta 2: Pandas


Enquanto o numpy lida com as opera√ß√µes num√©ricas, o pandas lida com a manipula√ß√£o de dados estruturados, como banco de dados, planilhas e tabelas. 


Mas o que o pandas faz? 


Ele **l√™**, **limpa**, **transforma**, **analisa** e **representa visualmente os dados em formato de tabelas**. As suas principais estruturas s√£o o DataFrame e a Series:

* DataFrame √© a tabela inteira
* Series √© uma coluna da tabela


### Pr√°tica com NumPy e Pandas


Agora que vimos o b√°sico de opera√ß√µes num√©ricas com NumPy, vamos usar o Pandas (que usa o NumPy por baixo dos panos) para importar, limpar e analisar um conjunto de dados.


Usaremos um conjunto de dados sobre diabetes (diabetes.csv).


Parte 1: Importando e Conhecendo os Dados


O primeiro passo √© carregar os dados para o ambiente de an√°lise e fazer uma primeira inspe√ß√£o, para conhecer os dados. 


Mas antes disso, vamos importar o pandas e o numpy, usando o comando:

```python
import pandas as pd
import numpy as np
```


Agora, vamos ler o arquivo CSV e criar uma "tabela" que o Pandas chama de DataFrame.

```python
df = pd.read_csv('diabetes.csv')
```


## Conhecendo os dados

```python
# Ver as primeiras 5 linhas da tabela
print(df.head())

# Ver o tamanho (linhas, colunas)
print(df.shape) # Resultado: (768, 9)

# Ver um resumo dos tipos de dados e se h√° valores nulos
print(df.info())
```


Conhecendo as Colunas:


- Pregnancies: N√∫mero de gesta√ß√µes.
- Glucose: N√≠vel de glicose no sangue.
- BloodPressure: Press√£o arterial.
- SkinThickness: Medida da dobra cut√¢nea.
- Insulin: N√≠vel de insulina.
- BMI: √çndice de Massa Corporal.
- DiabetesPedigreeFunction: Predisposi√ß√£o gen√©tica.
- Age: Idade.
- Outcome: Resultado (1 = tem diabetes, 0 = n√£o tem).


Parte 2: Limpeza e Tratamento dos Dados


A etapa de limpeza √© uma etapa fundamental, √© o momento em que verificamos se no nosso conjunto de dados h√° erros de digita√ß√£o, dados faltantes, tipo de dado errado. A limpeza garante que a nossa an√°lise seja confi√°vel.


Executando o¬†df.info(), vimos que N√ÉO h√° dados "faltantes" (NaN). 


Por√©m, ao investigar os dados mais adiante, usando o df.describe(), percebemos que os dados ausentes foram, na verdade, preenchidos com o n√∫mero zero (0).


Sendo assim, sabemos que √© fisicamente imposs√≠vel ter valor de glicose 0 ou de press√£o arterial 0. Ou seja, isso significa que existem dados faltantes no conjunto de dados.


Para resolver esse problema e tratar os dados vamos fazer as seguintes opera√ß√µes:
```python
# 1. Criar uma c√≥pia para n√£o alterar o original
df_tratado = df.copy()

# 2. Definir colunas onde '0' √© um dado faltante
colunas_problematicas = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']

# 3. Substituir '0' por 'NaN' (Not a Number), que √© o marcador correto
df_tratado[colunas_problematicas] = df_tratado[colunas_problematicas].replace(0, np.nan)

# 4. Verificar quantos dados faltantes (NaN) temos agora
print(df_tratado.isna().sum())
```


Agora sim vemos os dados faltantes. Dos 768 pacientes, 227 est√£o com o dado de medida da dobra cut√¢nea faltando, e 374 com o dado da insulina faltando.


Preenchendo os dados faltantes


Poder√≠amos substituir os dados ausentes por zero usando o comando:

```python
df=df.fillna (0)
```
Ent√£o, se tiver algum valor ausente, o fillna substitui por esse valor.
Ainda podemos tamb√©m usar a m√©dia, no entanto, como a m√©dia √© fortemente influenciada por valores extremos¬†(outliers), na nossa an√°lise optamos por usar a mediana. 


Lembre-se que a escolha da substitui√ß√£o depender√° muito do conjunto de dados que est√° em an√°lise.
```python
# 5. Lista das colunas que queremos preencher
colunas_para_limpar = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']

# 6. Loop: para cada coluna da lista...
for coluna in colunas_para_limpar:
    mediana = df_tratado[coluna].median() # Calcula a mediana
    df_tratado[coluna] = df_tratado[coluna].fillna(mediana) # Preenche os NaNs com a mediana

# 7. Verificar se limpamos tudo (deve dar tudo zero)
print(df_tratado.isnull().sum())
```


Verificando Dados Duplicados


Outro tipo de verifica√ß√£o √© ver se h√° algum dado (linhas repetidas) duplicado.


```python
# Verifica se h√° alguma linha duplicada (retorna 0 se n√£o houver)
print(df.duplicated().sum())
```


Havendo dados duplicados, o comando abaixo remove as linhas repetidas:


```python
# Comando para remover linhas duplicadas (apenas se houver)
# df.drop_duplicates(inplace=True)
```


Parte 3: Opera√ß√µes Num√©ricas e Estat√≠sticas


Para ter um resumo estat√≠stico das colunas num√©ricas, usamos:

```python
# Usamos o .describe() no DataFrame TRATADO
print(df_tratado.describe())
```


Dessa forma, obtemos o valor da m√©dia, desvio padr√£o, valor m√≠nimo, valor m√°ximo e os quartis de colunas, e assim temos um panorama da sa√∫de do grupo. Esse comando tamb√©m identifica outliers, simetria dos dados.


O resumo estat√≠stico geral √© muito √∫til, mas para fazer c√°lculos mais espec√≠ficos usamos o Numpy.¬†


Se quisermos, por exemplo, fazer um agrupamento? Comparando grupos diferentes...


Ex: Como as caracter√≠sticas dos pacientes com diabetes se comparam √†s dos pacientes sem diabetes?


Podemos agrupar os dados pela coluna Outcome (o resultado) e calcular a m√©dia de cada grupo.

```python
# Agrupa por 'Outcome' e calcula a m√©dia de todas as outras colunas
print(df_tratado.groupby('Outcome').mean())
```


Ao excutar, vemos que o n√≠vel m√©dio de 'Glucose' √© visivelmente maior no grupo 1 (142.13) isto √©, nos pacientes com diabetes, do que no grupo 0 (110.68) pacientes sem diabetes.


Esse tipo de agrupamento √© fundamental para identificar padr√µes.


Al√©m do resumo estat√≠stico geral, tamb√©m podemos entender como as vari√°veis se relacionam entre si e responder perguntas como:


Quais fatores t√™m maior rela√ß√£o com o diabetes? Ser√° que o n√≠vel de glicose aumenta conforme o IMC aumenta? 


Uma maneira de medir a for√ßa da rela√ß√£o √© calcular o coeficiente de correla√ß√£o, onde:
* Valor pr√≥ximo de 1: correla√ß√£o positiva forte
* Valor pr√≥ximo de -1: correla√ß√£o negativa forte.
* Valor pr√≥ximo de 0: Sem correla√ß√£o clara (fraca)


```python
# Calcula a matriz de correla√ß√£o
print(df_tratado.corr())
```


Analisando a linha Resultado (Outcome), notamos que a Glicose (Glucose) possui a correla√ß√£o positiva mais forte. Isso faz total sentido clinicamente, j√° que n√≠veis elevados de glicose s√£o o principal indicador usado para diagnosticar o diabetes.


Observe:


* Pregnancies: 0.221
* **Glucose: 0.492**
* BloodPressure: 0.165
* SkinThickness: 0.214
* Insulin: 0.203
* BMI: 0.312
* DiabetesPedigreeFunction: 0.173
* Age: 0.238


Nesta Sprint, n√≥s conseguimos:


1. Importar e preparar o conjunto de dados `diabetes.csv`.
2. Realizar a limpeza e tratamento de dados faltantes.
3. Extrair informa√ß√µes estat√≠sticas e descobrir que a Glicose tem a correla√ß√£o mais forte com o diagn√≥stico neste conjunto de dados.
   

Dominar essas t√©cnicas nos auxilia na tomada de decis√£o, no entendimento sobre o perfil de nossos pacientes e otimiza√ß√£o de tratamentos. 

