# ğŸ“˜ ClassificaÃ§Ã£o com Scikit-learn
Este **How to** apresenta uma introduÃ§Ã£o completa a modelos de classificaÃ§Ã£o, explicando conceitos, aplicaÃ§Ãµes, prÃ©-processamento, avaliaÃ§Ã£o de performance e implementaÃ§Ã£o prÃ¡tica em Python com scikit-learn.
## ğŸ“Œ O que Ã© ClassificaÃ§Ã£o?
ClassificaÃ§Ã£o Ã© uma tÃ©cnica de aprendizado supervisionado utilizada quando a variÃ¡vel alvo (y) Ã© categÃ³rica (categorias ou classes).
> ğŸ‘‰ Exemplo na Ã¡rea da saÃºde: diagnosticar se um paciente tem diabetes ou nÃ£o tem diabetes a partir de variÃ¡veis como idade, peso e histÃ³rico mÃ©dico.
### âš¡ DiferenÃ§a entre ClassificaÃ§Ã£o e RegressÃ£o
- ClassificaÃ§Ã£o â†’ prevÃª categorias (ex.: "Iris-setosa", "Iris-versicolor", "Iris-virginica").
- RegressÃ£o â†’ prevÃª valores contÃ­nuos (ex.: "nÃ­vel de glicose = 135 mg/dL").
### ğŸŒ¸ Exemplos de problemas resolvidos com ClassificaÃ§Ã£o
- DiagnÃ³stico de doenÃ§as â†’ prever se um paciente tem diabetes (sim/nÃ£o) com base em exames de sangue.
- DetecÃ§Ã£o de cÃ¢ncer â†’ classificar uma imagem de raio-X ou mamografia em cÃ¢ncer maligno ou benigno.
- Covid-19 â†’ identificar, a partir de sintomas e exames, se o paciente estÃ¡ infectado ou nÃ£o infectado.
- DoenÃ§as cardÃ­acas â†’ prever risco de infarto (alto risco, mÃ©dio risco, baixo risco).
- Exames laboratoriais â†’ classificar resultados em normal ou alterado.
- SaÃºde mental â†’ analisar questionÃ¡rios e classificar se a pessoa apresenta sinais de depressÃ£o ou nÃ£o.
- Triagem hospitalar â†’ categorizar pacientes em emergÃªncia, urgÃªncia ou nÃ£o urgente.

## ğŸ”¹ Principais Algoritmos de ClassificaÃ§Ã£o no Scikit-learn
### 1. RegressÃ£o LogÃ­stica (LogisticRegression)

- ğŸ“– Apesar do nome, Ã© classificador. Modela a probabilidade de pertencer a uma classe.

- âœ… Bom para problemas lineares e interpretÃ¡veis.

- ğŸ¥ Exemplo: prever se um paciente tem diabetes baseado em exames laboratoriais.

### 2. K-Nearest Neighbors (KNeighborsClassifier)

- ğŸ“– Classifica novos pontos com base nas classes dos k vizinhos mais prÃ³ximos.

- âœ… Simples, eficiente para datasets pequenos.

- ğŸ¥ Exemplo: classificar tipo de cÃ©lula comparando com cÃ©lulas conhecidas.

### 3. Support Vector Classifier (SVC)

- ğŸ“– Encontra o hiperplano que separa melhor as classes.

- âœ… Excelente para problemas lineares e nÃ£o lineares usando kernel.

- ğŸ¥ Exemplo: identificar pacientes de alto risco com base em mÃºltiplos fatores.

### 4. Decision Tree Classifier (DecisionTreeClassifier)

- ğŸ“– Divide os dados usando regras de decisÃ£o em Ã¡rvore.

- âœ… FÃ¡cil de interpretar e visualizar.

- ğŸ¥ Exemplo: decidir se um paciente deve receber um tratamento especÃ­fico.

### 5. Random Forest Classifier (RandomForestClassifier)

- ğŸ“– Conjunto de Ã¡rvores de decisÃ£o que votam na classe final.

- âœ… Mais robusto que uma Ã¡rvore individual.

- ğŸ¥ Exemplo: prever diagnÃ³stico de doenÃ§a baseado em mÃºltiplos exames.

### 6. Gradient Boosting Classifier (GradientBoostingClassifier)

- ğŸ“– Cria Ã¡rvores sequenciais, cada uma corrigindo os erros da anterior.

- âœ… Alta performance em dados tabulares.

- ğŸ¥ Exemplo: classificar risco de complicaÃ§Ãµes hospitalares.

### 7. AdaBoost Classifier (AdaBoostClassifier)

- ğŸ“– DÃ¡ mais peso a exemplos onde o modelo anterior errou.

- âœ… Bom para lidar com ruÃ­do moderado.

- ğŸ¥ Exemplo: prever readmissÃ£o hospitalar em casos inconsistentes.

### 8. Naive Bayes (GaussianNB)

- ğŸ“– Baseado no teorema de Bayes, assume independÃªncia entre atributos.

- âœ… Simples, rÃ¡pido e funciona bem com pequenas amostras.

- ğŸ¥ Exemplo: classificar pacientes com base em sintomas.

| Modelo                     | DescriÃ§Ã£o                | Vantagens                | Desvantagens                           | Exemplo em SaÃºde          |
|-----------------------------|--------------------------|--------------------------|----------------------------------------|--------------------------|
| LogisticRegression         | Probabilidade de classe  | InterpretÃ¡vel            | Linear, nÃ£o captura relaÃ§Ãµes complexas | DiagnÃ³stico de diabetes   |
| KNeighborsClassifier       | Vizinhos mais prÃ³ximos   | Simples, nÃ£o paramÃ©trico | Lento com muitos dados                 | ClassificaÃ§Ã£o de cÃ©lulas  |
| SVC                        | Hiperplano separador     | NÃ£o linear, robusto      | Pode ser lento em grandes bases        | Risco de complicaÃ§Ãµes     |
| DecisionTreeClassifier     | Regras de decisÃ£o        | FÃ¡cil de interpretar     | Overfitting                            | DecisÃ£o de tratamento     |
| RandomForestClassifier     | Floresta de Ã¡rvores      | Robusto, generaliza bem  | Menos interpretÃ¡vel                    | DiagnÃ³stico complexo      |
| GradientBoostingClassifier | Ãrvores sequenciais      | Alta performance         | Mais lento que Random Forest           | Risco hospitalar          |
| AdaBoostClassifier         | ReponderaÃ§Ã£o de exemplos | Lida bem com ruÃ­do       | SensÃ­vel a outliers extremos           | ReadmissÃ£o hospitalar     |
| GaussianNB                 | Probabilidade com Bayes  | Simples e rÃ¡pido         | SupÃµe independÃªncia                    | ClassificaÃ§Ã£o de sintomas |


## ğŸŒ¸ Dataset Iris (Scikit-learn)
O dataset Iris Ã© um clÃ¡ssico de classificaÃ§Ã£o. ContÃ©m 150 flores de 3 espÃ©cies:

- **Iris-setosa**

- **Iris-versicolor**

- **Iris-virginica**

Cada flor possui 4 caracterÃ­sticas:

- Sepal Length (cm)

- Sepal Width (cm)

- Petal Length (cm)

- Petal Width (cm)

> Objetivo: prever a espÃ©cie da flor com base nas medidas das pÃ©talas e sÃ©palas.

### ğŸ’» Carregando o dataset
```
from sklearn.datasets import load_iris
iris = load_iris()

X = iris.data      # Features (4 colunas)
y = iris.target    # Classes (0=setosa, 1=versicolor, 2=virginica)

print("Formato de X:", X.shape)  # (150, 4)
print("Formato de y:", y.shape)  # (150,)
```
### ğŸ§¹ PrÃ©-processamento dos Dados
Antes de treinar, os dados precisam ser preparados:
> O scikit learn jÃ¡ traz os dados do dataset `iris` prÃ©-processado, contudo  Ã© recomendado reconferir, alÃ©m de que, para outros datasets, esses passos serÃ£o de suma importÃ¢ncia.

> Para mais informaÃ§Ãµes sobre prÃ©- processamento de dados volte a [PrÃ© Processamento](https://github.com/GabryelleDart/How-To-train-and-evaluate-a-classification-model-using-scikit-learn/tree/main/Pr%C3%A9-Processamento) .

1. InspeÃ§Ã£o inicial

    - Identificar tipos de dados, valores faltantes, outliers.

    - Ferramentas: df.info(), df.describe().

2. Tratar valores faltantes

    - Remover linhas/colunas incompletas.

    - Preencher com mÃ©dia/mediana (SimpleImputer).

3. Transformar variÃ¡veis categÃ³ricas

    - Ex.: â€œfuma = sim/nÃ£oâ€ â†’ converter para 0 e 1.

    - Usar OneHotEncoder ou pd.get_dummies.

4. Escalonar variÃ¡veis

    - PadrÃ£o comum: StandardScaler ou MinMaxScaler.

5. Separar dados de treino e teste
### ğŸ“ Treinando um modelo de classificaÃ§Ã£o
O KNN (K-Nearest Neighbors) Ã© um dos algoritmos mais simples de classificaÃ§Ã£o. Ele funciona de maneira muito intuitiva:
> Imagine que vocÃª estÃ¡ em um jardim cheio de flores de diferentes espÃ©cies. Uma nova flor aparece e vocÃª quer descobrir a qual espÃ©cie ela pertence.
> O KNN olha para as K flores mais prÃ³ximas dela (os vizinhos mais prÃ³ximos) e vota qual espÃ©cie Ã© mais comum entre esses vizinhos. A espÃ©cie mais frequente serÃ¡ a previsÃ£o do modelo.
```
    from sklearn.neighbors import KNeighborsClassifier
    
    
    knn = KNeighborsClassifier(n_neighbors=3)

```
> ğŸ– **n_neighbors=3** significa que o modelo vai olhar para as **3 flores mais prÃ³ximas** e escolher a espÃ©cie que aparecer mais vezes.

Treinar o modelo significa ensinar o KNN usando os dados de treino. Ele vai "memorizar" as posiÃ§Ãµes das flores no espaÃ§o das caracterÃ­sticas para que possa comparar com novas flores depois.
```
    knn.fit(X_train, y_train)

```
> âœ… Aqui, nÃ£o hÃ¡ magia de cÃ¡lculos complexos: o KNN apenas memoriza os exemplos de treino e suas classes.

> ğŸ“Œ Diferente de regressÃ£o linear, ele nÃ£o tenta desenhar uma linha, ele se baseia na proximidade.

### ğŸ“ PrevisÃµes
Agora podemos dar flores do conjunto de teste e perguntar ao KNN: â€œQual espÃ©cie vocÃª acha que essa flor Ã©?â€
```
    y_pred = knn.predict(X_test)
    print("PrevisÃµes do KNN:", y_pred)

```
> ğŸ’¡ Cada nÃºmero na lista y_pred representa a classe prevista:

> 0 â†’ Iris-setosa, 1 â†’ Iris-versicolor, 2 â†’ Iris-virginica

### ğŸ“ˆ AvaliaÃ§Ã£o da Performance
ApÃ³s treinar um modelo de classificaÃ§Ã£o, nÃ£o basta apenas prever: precisamos saber se ele realmente funciona. Essa etapa Ã© chamada de avaliaÃ§Ã£o do desempenho.

#### ğŸ”¹ O que significa avaliar o desempenho?
Avaliar o desempenho significa medir quÃ£o bem o modelo acerta as previsÃµes quando recebe novos dados que ele nunca viu antes.
> Analogia: Ã© como ensinar uma crianÃ§a a identificar frutas. Depois, vocÃª mostra novas frutas que ela nunca viu e confere se ela consegue acertar o tipo de fruta.

No contexto do KNN com o dataset Iris:
- O modelo viu algumas flores (treino).
- Agora ele tenta prever a espÃ©cie das flores do teste.
- AvaliaÃ§Ã£o mede quantas ele acertou e onde errou.

#### ğŸ”¹ Por que precisamos avaliar?

Avaliar Ã© essencial porque:
1. Saber a qualidade do modelo â†’ sem avaliaÃ§Ã£o, nÃ£o temos certeza se as previsÃµes sÃ£o confiÃ¡veis.
2. Evitar overfitting â†’ o modelo pode aprender â€œdecorandoâ€ o treino e falhar em dados novos.
3. Comparar diferentes modelos â†’ por exemplo, KNN vs Logistic Regression.
4. Tomada de decisÃ£o â†’ mÃ©dicos, cientistas ou sistemas precisam confiar nas previsÃµes.

> Exemplo: se KNN acerta 95% das flores do teste, podemos confiar nele; se acerta apenas 60%, precisamos melhorar ou testar outro algoritmo.

#### ğŸ”¹ Para que serve a avaliaÃ§Ã£o?

- Identificar erros â†’ saber quais classes o modelo confunde mais.

- Ajustar parÃ¢metros â†’ como o nÃºmero de vizinhos no KNN (n_neighbors).

- Comparar algoritmos â†’ escolher o modelo mais adequado para o problema.

- Comunicar resultados â†’ fornecer mÃ©tricas compreensÃ­veis para leigos ou gestores.

#### ğŸ”¹Formas de avaliar modelos de classificaÃ§Ã£o
1. **AcurÃ¡cia (Accuracy)**

    - % de previsÃµes corretas.
    
    - FÃ¡cil de entender, mas pode ser enganosa se classes estiverem desbalanceadas.

2. **Matriz de ConfusÃ£o (Confusion Matrix)**
    - Tabela que mostra acertos e erros por classe.
    - Linhas â†’ classe real, colunas â†’ classe prevista.

3. **Precision, Recall e F1-score**
    - Precision â†’ proporÃ§Ã£o de acertos entre os exemplos previstos como positiva.
    - Recall â†’ proporÃ§Ã£o de acertos entre os exemplos realmente positivos.
    - F1-score â†’ mÃ©dia harmÃ´nica entre precision e recall, Ãºtil para dados desbalanceados.

4. **Cross-validation (validaÃ§Ã£o cruzada)**
    - Divide os dados em vÃ¡rias partes e treina/testa vÃ¡rias vezes.
    - DÃ¡ uma medida mais robusta da performance.
```
    from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
    
    accuracy = accuracy_score(y_test, y_pred)
    print("AcurÃ¡cia:", accuracy)
    
    cm = confusion_matrix(y_test, y_pred)
    print("Matriz de ConfusÃ£o:\n", cm)
    
    report = classification_report(y_test, y_pred, target_names=iris.target_names)
    print("RelatÃ³rio de ClassificaÃ§Ã£o:\n", report)

```
> ğŸ”¹ Interpretando a matriz de confusÃ£o:
> - Cada linha representa a classe real.
> - Cada coluna representa a classe prevista.
> - O ideal Ã© que todos os nÃºmeros estejam na diagonal principal (acertos).
      
> ğŸ”¹ Exemplo de interpretaÃ§Ã£o:
> - Se a matriz mostra que algumas versicolor foram classificadas como virginica, isso indica que o modelo confundiu essas duas espÃ©cies.
> - A acurÃ¡cia geral mostra quanto ele acerta em porcentagem.

#### ğŸ”¹ O que define se foi bem avaliado ou nÃ£o?
- AcurÃ¡cia alta â†’ modelo previsivelmente correto.

- Erros mÃ­nimos em classes importantes â†’ especialmente em saÃºde ou seguranÃ§a, certos erros podem ser mais crÃ­ticos.

- F1-score equilibrado â†’ modelo nÃ£o Ã© apenas bom para uma classe, mas funciona bem para todas.

- Matriz de confusÃ£o clara â†’ poucas confusÃµes entre classes.

### ğŸ“ Dicas Importantes para ClassificaÃ§Ã£o
- Sempre verifique o balanceamento das classes; classes desbalanceadas podem prejudicar o modelo.
- Use cross-validation para avaliar robustez do modelo.
- Experimente diferentes algoritmos e compare acurÃ¡cia e F1-score.
- Para problemas reais, trate valores faltantes, outliers e escalonamento cuidadosamente.
- Para modelos complexos (Random Forest, Boosting), use feature importance para interpretar os fatores mais relevantes.
