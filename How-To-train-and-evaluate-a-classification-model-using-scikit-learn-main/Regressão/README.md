# ğŸ“˜ RegressÃ£o com Scikit-learn

Este guia apresenta uma introduÃ§Ã£o completa a modelos de regressÃ£o, explicando conceitos, aplicaÃ§Ãµes, prÃ©-processamento, avaliaÃ§Ã£o de performance e implementaÃ§Ã£o prÃ¡tica em Python com scikit-learn

## ğŸ“Œ O que Ã© RegressÃ£o?
RegressÃ£o Ã© uma tÃ©cnica de aprendizado supervisionado utilizada quando a variÃ¡vel alvo (y) Ã© contÃ­nua (valores numÃ©ricos).

> ğŸ‘‰ Exemplo na Ã¡rea da saÃºde: prever o nÃ­vel de glicose no sangue de um paciente a partir de variÃ¡veis como idade, peso e hÃ¡bitos de vida.

### DiferenÃ§a para ClassificaÃ§Ã£o

- ClassificaÃ§Ã£o â†’ prevÃª categorias (ex.: "tem diabetes" ou "nÃ£o tem diabetes").

- RegressÃ£o â†’ prevÃª valores contÃ­nuos (ex.: "nÃ­vel de glicose = 135 mg/dL").

## ğŸ¥ Exemplos de problemas resolvidos com RegressÃ£o

- PrevisÃ£o do nÃ­vel de colesterol com base em dieta e exercÃ­cios.

- Estimativa da pressÃ£o arterial a partir de idade e IMC.

- CÃ¡lculo do tempo de internaÃ§Ã£o hospitalar.

- ProgressÃ£o de tumores em mmÂ³ ao longo do tempo.

## ğŸ”¹ Algoritmos de RegressÃ£o no Scikit-learn
### 1. RegressÃ£o Linear (LinearRegression)

- ğŸ“– O modelo mais simples: assume que a relaÃ§Ã£o entre variÃ¡veis Ã© linear (reta ou hiperplano).

- âœ… Bom para dados simples e quando queremos interpretabilidade (coeficientes mostram a importÃ¢ncia de cada variÃ¡vel).

- ğŸ¥ Exemplo em saÃºde: prever pressÃ£o arterial a partir de idade e IMC.

### 2. Ridge Regression (Ridge)

- ğŸ“– Variante da regressÃ£o linear com regularizaÃ§Ã£o L2 (penaliza coeficientes grandes).

- âœ… Ajuda a evitar overfitting quando temos muitas variÃ¡veis.

- ğŸ¥ Exemplo: prever nÃ­veis de colesterol a partir de exames laboratoriais diversos.

### 3. Lasso Regression (Lasso)

- ğŸ“– Variante da linear com regularizaÃ§Ã£o L1 (pode zerar coeficientes irrelevantes â†’ seleÃ§Ã£o de variÃ¡veis automÃ¡tica).

- âœ… Bom para datasets com muitas variÃ¡veis irrelevantes.

- ğŸ¥ Exemplo: identificar quais exames sÃ£o realmente relevantes para prever glicose.

### 4. Elastic Net (ElasticNet)

- ğŸ“– Combina L1 (Lasso) e L2 (Ridge).

- âœ… Mais flexÃ­vel: pode ao mesmo tempo selecionar variÃ¡veis e evitar overfitting.

- ğŸ¥ Exemplo: prever risco de diabetes combinando exames laboratoriais e fatores de estilo de vida.

### 5. RegressÃ£o Polinomial (PolynomialFeatures + LinearRegression)

- ğŸ“– Expande variÃ¡veis para potÃªncias maiores (xÂ², xÂ³â€¦) e aplica regressÃ£o linear.

- âœ… Ãštil quando a relaÃ§Ã£o nÃ£o Ã© uma reta, mas uma curva.

- ğŸ¥ Exemplo: crescimento de um tumor que segue curva quadrÃ¡tica, nÃ£o linear.

### 6. Ãrvore de RegressÃ£o (DecisionTreeRegressor)

- ğŸ“– Divide os dados em regras de decisÃ£o (se idade > 50 e IMC > 30 â†’ risco maior).

- âœ… FÃ¡cil de interpretar, mas pode superajustar (overfitting).

- ğŸ¥ Exemplo: prever tempo de internaÃ§Ã£o hospitalar baseado em condiÃ§Ãµes prÃ©-existentes.

### 7. Random Forest Regressor (RandomForestRegressor)

- ğŸ“– Conjunto de vÃ¡rias Ã¡rvores (floresta).

- âœ… Mais robusto que uma Ã¡rvore sÃ³, generaliza melhor.

- ğŸ¥ Exemplo: prever tempo de recuperaÃ§Ã£o pÃ³s-cirurgia a partir de vÃ¡rios fatores.

### 8. Gradient Boosting Regressor (GradientBoostingRegressor)

- ğŸ“– Cria Ã¡rvores de forma sequencial, cada uma corrigindo os erros da anterior.

- âœ… Excelente desempenho em dados tabulares, muitas vezes melhor que Random Forest.

- ğŸ¥ Exemplo: prever nÃ­veis de glicose ao longo do tempo com base em histÃ³rico clÃ­nico.

### 9. AdaBoost Regressor (AdaBoostRegressor)

- ğŸ“– Similar ao Gradient Boosting, mas dÃ¡ mais peso a exemplos onde o modelo anterior errou.

- âœ… Bom para dados com ruÃ­do moderado.

- ğŸ¥ Exemplo: prever pressÃ£o arterial em pacientes onde alguns dados sÃ£o inconsistentes.

### 10. HistGradientBoosting Regressor (HistGradientBoostingRegressor)

- ğŸ“– VersÃ£o otimizada do Gradient Boosting, muito rÃ¡pida e eficiente para grandes datasets.

- âœ… EscalÃ¡vel para milhÃµes de amostras.

- ğŸ¥ Exemplo: prever custos hospitalares em grandes bases de dados de saÃºde pÃºblica.

### 11. K-Nearest Neighbors Regressor (KNeighborsRegressor)

- ğŸ“– Usa a mÃ©dia dos k vizinhos mais prÃ³ximos para prever.

- âœ… Simples, nÃ£o assume forma da funÃ§Ã£o.

- âŒ Fica lento com muitos dados.

- ğŸ¥ Exemplo: prever nÃ­vel de glicose de um paciente comparando com pacientes similares.

### 12. Support Vector Regressor (SVR)

- ğŸ“– Usa mÃ¡quinas de vetores de suporte para prever, podendo usar funÃ§Ãµes de kernel (linear, polinomial, radial).

- âœ… Bom para dados complexos e nÃ£o lineares.

- âŒ Pode ser lento em datasets grandes.

- ğŸ¥ Exemplo: prever progressÃ£o da diabetes em pacientes com muitos fatores interdependentes.

### 13. Bayesian Ridge Regression (BayesianRidge)

- ğŸ“– RegressÃ£o linear com abordagem bayesiana: fornece incerteza das previsÃµes.

- âœ… Ãštil quando queremos intervalos de confianÃ§a.

- ğŸ¥ Exemplo: prever nÃ­veis de colesterol e dar uma margem de incerteza (ex.: 180 Â± 15).

### 14. Huber Regressor (HuberRegressor)

- ğŸ“– Combina vantagens da regressÃ£o linear e robustez contra outliers.

- âœ… Melhor que linear quando hÃ¡ valores extremos nos dados.

- ğŸ¥ Exemplo: prever pressÃ£o arterial ignorando medidas erradas de alguns pacientes.

### 15. Theil-Sen Regressor (TheilSenRegressor)

- ğŸ“– MÃ©todo robusto que usa medianas em vez de mÃ©dias, resistente a outliers.

- âœ… Bom para pequenas bases de dados com ruÃ­dos.

- ğŸ¥ Exemplo: prever peso fetal em um estudo pequeno, com algumas medidas imprecisas.

### 16. RANSAC Regressor (RANSACRegressor)

- ğŸ“– Ajusta o modelo vÃ¡rias vezes, descartando pontos que parecem outliers.

- âœ… Excelente para dados com muitos erros de mediÃ§Ã£o.

- ğŸ¥ Exemplo: prever taxa de crescimento tumoral, ignorando exames claramente errados.

| Modelo                          | DescriÃ§Ã£o                           | Vantagens                         | Desvantagens                    | Exemplo em SaÃºde |
|---------------------------------|-------------------------------------|-----------------------------------|----------------------------------|------------------|
| LinearRegression                | Modelo linear simples               | InterpretaÃ§Ã£o fÃ¡cil                | NÃ£o captura relaÃ§Ãµes complexas   | PressÃ£o arterial vs idade |
| Ridge                           | Linear com regularizaÃ§Ã£o L2         | Evita overfitting                  | DifÃ­cil interpretar coeficientes | Colesterol vs exames |
| Lasso                           | Linear com regularizaÃ§Ã£o L1         | Seleciona variÃ¡veis automaticamente| Pode zerar variÃ¡veis importantes | SeleÃ§Ã£o de exames para prever glicose |
| ElasticNet                      | Combina Lasso e Ridge               | FlexÃ­vel e equilibrado             | Mais parÃ¢metros para ajustar     | Risco de diabetes |
| Polynomial Regression           | Linear com termos polinomiais       | Captura curvas                     | Pode overfittar                  | Crescimento tumoral |
| DecisionTreeRegressor           | Baseado em regras                   | FÃ¡cil de interpretar               | Overfitting                      | Tempo de internaÃ§Ã£o |
| RandomForestRegressor           | Conjunto de Ã¡rvores                 | Robusto, bom desempenho            | Menos interpretÃ¡vel              | RecuperaÃ§Ã£o pÃ³s-cirurgia |
| GradientBoostingRegressor       | Ãrvores sequenciais                 | Alta performance                   | Mais lento que Random Forest     | ProgressÃ£o da diabetes |
| AdaBoostRegressor               | Ãrvores com reponderaÃ§Ã£o            | Lida bem com ruÃ­do                 | Pode falhar com outliers extremos| PressÃ£o arterial |
| HistGradientBoostingRegressor   | Boosting otimizado                  | Muito rÃ¡pido e escalÃ¡vel           | Menos interpretÃ¡vel              | Custos hospitalares |
| KNeighborsRegressor             | MÃ©dia dos vizinhos                  | Simples, nÃ£o assume funÃ§Ã£o         | Lento em grandes bases           | Glicose de pacientes similares |
| SVR                             | RegressÃ£o por vetores de suporte    | Bom para dados nÃ£o lineares        | Lento em bases grandes           | ProgressÃ£o da diabetes |
| BayesianRidge                   | Linear Bayesiana                    | DÃ¡ intervalo de incerteza          | Mais complexo de interpretar     | Colesterol Â± incerteza |
| HuberRegressor                  | Linear robusta                      | Resiste a outliers                 | Menos precisa sem outliers       | PressÃ£o arterial com medidas erradas |
| TheilSenRegressor               | Linear robusta com medianas         | Resistente a ruÃ­dos                | Lento em bases grandes           | Peso fetal em bases pequenas |
| RANSACRegressor                 | Ajuste robusto a outliers           | Excelente com erros de mediÃ§Ã£o     | Pode descartar bons pontos       | Crescimento tumoral com erros |


## ğŸ“˜ Dataset Diabetes (Scikit-learn)
O dataset Diabetes Ã© um conjunto de dados real usado para estudos de regressÃ£o. Ele contÃ©m informaÃ§Ãµes de 442 pacientes, cada um descrito por 10 variÃ¡veis clÃ­nicas (idade, sexo, IMC, pressÃ£o arterial, exames de sangue etc.).

O que queremos prever Ã© um nÃºmero contÃ­nuo:
    â¡ï¸ A progressÃ£o da doenÃ§a apÃ³s 1 ano.

> ğŸ‘‰ Ou seja, dado um paciente, tentamos prever o quanto a diabetes pode evoluir em 1 ano.
### Estrutura dos dados
  - X (features) â†’ matriz com 442 linhas (pacientes) Ã— 10 colunas (atributos).

  - y (target) â†’ vetor com 442 valores, representando a progressÃ£o da doenÃ§a.
    
### ğŸ’» Carregando o dataset:
```
    from sklearn.datasets import load_diabetes
    diabetes = load_diabetes()

    # X = dados clÃ­nicos (features), y = progressÃ£o da doenÃ§a (target)
    X = diabetes.data
    y = diabetes.target

    print("Formato de X:", X.shape)  # (442, 10)
    print("Formato de y:", y.shape)  # (442,)
```

## ğŸ§¹ PrÃ©-processamento dos Dados
Antes de treinar, os dados precisam ser preparados:
> O scikit learn jÃ¡ traz os dados do dataset `diabetes` prÃ©-processado, contudo  Ã© recomendado reconferir, alÃ©m de que, para outros datasets, esses passos serÃ£o de suma importÃ¢ncia.

> Para mais informaÃ§Ãµes sobre prÃ©- processamento de dados volte a [PrÃ© Processamento](https://github.com/GabryelleDart/How-To-train-and-evaluate-a-classification-model-using-scikit-learn/tree/main/Pr%C3%A9-Processamento) .

1. InspeÃ§Ã£o inicial

    - Identificar tipos de dados, valores faltantes, outliers.

    - Ferramentas: df.info(), df.describe().

2. Tratar valores faltantes

    - Remover linhas/colunas incompletas.

    - Preencher com mÃ©dia/mediana (SimpleImputer).

3. Transformar variÃ¡veis categÃ³ricas

    - Ex.: â€œfuma = sim/nÃ£oâ€ â†’ converter para 0 e 1.

    - Usar OneHotEncoder ou pd.get_dummies.

4. Escalonar variÃ¡veis

    - PadrÃ£o comum: StandardScaler ou MinMaxScaler.

5. Separar dados de treino e teste
```
    from sklearn.model_selection import train_test_split

    X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
# 80% dos pacientes â†’ treino
# 20% dos pacientes â†’ teste
```
### ğŸ“ Treinando um modelo de regressÃ£o linear com Diabetes dataset
Aqui vamos usar RegressÃ£o Linear.
Ele tenta encontrar uma linha de tendÃªncia que melhor explica a relaÃ§Ã£o entre as caracterÃ­sticas dos pacientes e a gravidade da diabetes.
```
  from sklearn.linear_model import LinearRegression

  model = LinearRegression()

```
Agora o modelo irÃ¡ aprender a relaÃ§Ã£o entre as caracterÃ­sticas dos pacientes (idade, pressÃ£o etc.) e a gravidade da doenÃ§a.
```
  model.fit(X_train, y_train)

```
### ğŸ“ PrevisÃµes
Com o modelo treinado, agora damos os dados de pacientes do teste (que ele nunca viu) e pedimos:
â€œQual seria o valor da gravidade para este paciente?â€
```
 y_pred = model.predict(X_test)

```
### ğŸ“ˆ AvaliaÃ§Ã£o da Performance
Quando treinamos um modelo de machine learning (classificaÃ§Ã£o ou regressÃ£o), nÃ£o basta sÃ³ treinar: precisamos saber se ele realmente funciona. Ã‰ aqui que entra a avaliaÃ§Ã£o da performance.

> NÃ£o adianta sÃ³ prever, temos que medir o quÃ£o prÃ³ximo o modelo ficou da realidade.

#### ğŸ”¹ O que significa avaliar a performance?
Avaliar a performance significa medir quÃ£o bem o modelo consegue fazer previsÃµes corretas em dados que ele nÃ£o viu durante o treino.

Exemplo :

- O modelo tenta prever o nÃ­vel de glicose de pacientes.
- Se o modelo prever 140 mg/dL e o valor real for 145 mg/dL, o erro Ã© 5 mg/dL.
- Avaliar o desempenho consiste em resumir esses erros para todos os pacientes e entender se o modelo Ã© confiÃ¡vel.
  
> âš ï¸ Lembre-se: treinar o modelo e avaliar nos mesmos dados Ã© enganoso. O modelo pode simplesmente â€œdecorarâ€ os exemplos.

#### ğŸ”¹Por que precisamos avaliar?
Avaliar Ã© essencial porque:

1. Medimos a qualidade do modelo â†’ nÃ£o adianta ter um modelo se ele nÃ£o funciona na prÃ¡tica.

2. Evitamos overfitting â†’ o modelo pode aprender â€œtruquesâ€ dos dados de treino que nÃ£o funcionam em novos pacientes.

3. Comparamos modelos â†’ saber qual algoritmo Ã© mais adequado para o problema.
4. Ajudamos na tomada de decisÃ£o â†’ mÃ©dicos, gestores ou sistemas precisam confiar nas previsÃµes.

Exemplo:
> Um modelo que prevÃª diabetes errado 80% das vezes Ã© inÃºtil na prÃ¡tica clÃ­nica, mesmo que tenha sido treinado com muitos dados.

#### ğŸ”¹MÃ©tricas comuns para regressÃ£o:

- MAE (Mean Absolute Error) â†’ erro mÃ©dio em unidades reais.

- MSE (Mean Squared Error) â†’ penaliza mais erros grandes.

- RMSE (Root Mean Squared Error) â†’ interpretaÃ§Ã£o fÃ¡cil (mesma unidade do alvo).

- RÂ² (Coeficiente de determinaÃ§Ã£o) â†’ quanto da variaÃ§Ã£o do alvo o modelo explica (0 a 1).

```
  from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
  import numpy as np
  
  mae = mean_absolute_error(y_test, y_pred)
  rmse = np.sqrt(mean_squared_error(y_test, y_pred))
  r2 = r2_score(y_test, y_pred)
  
  print("MAE:", mae)
  print("RMSE:", rmse)
  print("RÂ²:", r2)

```
- Se o RÂ² for alto (perto de 1), significa que o modelo explica bem a gravidade da diabetes.

- Se for baixo (perto de 0), significa que as informaÃ§Ãµes que temos nÃ£o sÃ£o suficientes para prever bem.

- Os erros (MAE, RMSE) mostram o quanto o modelo erra em mÃ©dia.
